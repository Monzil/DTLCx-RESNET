{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hb1llR2y4RUY"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential,Model\n",
        "from tensorflow.keras.layers import Dense,Dropout,Flatten,BatchNormalization\n",
        "from tensorflow.keras.applications.vgg16 import VGG16,preprocess_input\n",
        "from keras.applications.resnet_v2 import ResNet50V2\n",
        "#from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.applications.resnet_v2 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxLH_TUV4nvb",
        "outputId": "96e198f6-2724-4ab0-f5c0-8095d24aef3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_dir=\"/content/drive/MyDrive/ctfolder/Fold3/train\"\n",
        "validation_data_dir=\"/content/drive/MyDrive/ctfolder/Fold3/test\"\n",
        "img_width=224\n",
        "img_height=224\n",
        "batch_size=32"
      ],
      "metadata": {
        "id": "FOew0Vj94vo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "train_generator = datagen.flow_from_directory(directory=train_data_dir,\n",
        "                                              target_size = (img_width, img_height),\n",
        "                                              classes=['covid','normal'],\n",
        "                                              class_mode = 'binary',\n",
        "                                              batch_size=batch_size)\n",
        "\n",
        "validation_generator = datagen.flow_from_directory(directory=validation_data_dir,\n",
        "                                              target_size = (img_width, img_height),\n",
        "                                              classes=['covid','normal'],\n",
        "                                              class_mode = 'binary',\n",
        "                                              batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0d8MHsU5SAv",
        "outputId": "fe97bf0c-4cb2-4446-f79b-0c457f3c4a13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 800 images belonging to 2 classes.\n",
            "Found 200 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vgg_arch=ResNet50V2(input_shape=(img_width,img_height,3),weights=\"imagenet\",include_top=False)"
      ],
      "metadata": {
        "id": "ttSY55265j8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layers in vgg_arch.layers:\n",
        "  layers.trainable=False"
      ],
      "metadata": {
        "id": "mWrquI_N5q6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(vgg_arch)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128,activation='relu',))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(1,activation=\"sigmoid\", name='visualized_layer'))\n",
        "#model.add(Dense( 2, activation='sigmoid', name='visualized_layer'))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "V7jwgUsm56t5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n"
      ],
      "metadata": {
        "id": "8KYpM8Nx6Qjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "B6UUcUbJ6V-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit_generator(generator=train_generator, steps_per_epoch=len(train_generator), epochs = 5, \n",
        "                              validation_data=validation_generator, validation_steps=len(validation_generator),\n",
        "                            verbose= 1\n",
        "                              )"
      ],
      "metadata": {
        "id": "zsqJtXeu6iZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tf-keras-vis tensorflow"
      ],
      "metadata": {
        "id": "VwV5D1aB-st2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.applications.vgg16 import VGG16 as Model\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "# %matplotlib inline\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras import backend as K\n",
        "from tf_keras_vis.saliency import Saliency\n",
        "from tf_keras_vis.utils import normalize\n",
        "from vis.utils import utils\n",
        "from tensorflow.keras.applications.vgg16 import decode_predictions\n",
        "import json"
      ],
      "metadata": {
        "id": "rjFvprOq-wqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#utility function to show images\n",
        "def display_imgs(images):\n",
        "  subprot_args = {\n",
        "   'nrows': 1,\n",
        "   'ncols': 4,\n",
        "   'figsize': (6, 3),\n",
        "   'subplot_kw': {'xticks': [], 'yticks': []}\n",
        "  }\n",
        "  f, ax = plt.subplots(**subprot_args)\n",
        "  for i in range(len(images)):\n",
        "    ax[i].imshow(images[i])\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "Z7a7BJCm-7Tt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load images\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "img1 = load_img('/content/drive/MyDrive/ctfolder/Fold3/test/covid/covid400.png', target_size=(224, 224))\n",
        "img2 = load_img('/content/drive/MyDrive/ctfolder/Fold3/test/covid/covid401.png', target_size=(224, 224))\n",
        "img3 = load_img('/content/drive/MyDrive/ctfolder/Fold3/test/covid/covid402.png', target_size=(224, 224))\n",
        "img4 = load_img('/content/drive/MyDrive/ctfolder/Fold3/test/covid/covid403.png', target_size=(224, 224))"
      ],
      "metadata": {
        "id": "gb96IcoA9wlo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = np.asarray([np.array(img1), np.array(img2), np.array(img3), np.array(img4)])\n",
        "display_imgs(images)"
      ],
      "metadata": {
        "id": "VCmxsPdD-Vou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#convert to numpy array for reshaping\n",
        "#convert to numpy array for reshaping\n",
        "img1 = img_to_array(img1)\n",
        "img2 = img_to_array(img2)\n",
        "img3 = img_to_array(img3)\n",
        "img4 = img_to_array(img4)"
      ],
      "metadata": {
        "id": "TcRVtZcJ_NKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#reshape to prepare for processing\n",
        "img1 = img1.reshape(1,224,224,3)\n",
        "img2 = img2.reshape(1,224,224,3)\n",
        "img3 = img3.reshape(1,224,224,3)\n",
        "img4 = img4.reshape(1,224,224,3)"
      ],
      "metadata": {
        "id": "H98TtmFt_Wr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#preprocess to prepare for input\n",
        "img1 = preprocess_input(img1)\n",
        "img2 = preprocess_input(img2)\n",
        "img3 = preprocess_input(img3)\n",
        "img4 = preprocess_input(img4)"
      ],
      "metadata": {
        "id": "yWvOAWZx_bOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predictions with input images\n",
        "yhat1 = model.predict(img1)\n",
        "yhat2 = model.predict(img2)\n",
        "yhat3 = model.predict(img3)\n",
        "yhat4 = model.predict(img4)"
      ],
      "metadata": {
        "id": "kbKL3dY2_g8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#decode predictions\n",
        "label1 = decode_predictions(yhat1)\n",
        "label2 = decode_predictions(yhat2)\n",
        "label3 = decode_predictions(yhat3)\n",
        "label4 = decode_predictions(yhat4)"
      ],
      "metadata": {
        "id": "10qJfqN5E4oN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extract top most prediction for each input\n",
        "label1 = label1[0][0]\n",
        "label2 = label2[0][0]\n",
        "label3 = label3[0][0]\n",
        "label4 = label4[0][0]"
      ],
      "metadata": {
        "id": "mfIcSeObGhYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# swap softmax layer with linear layer \n",
        "layer_idx = utils.find_layer_idx(model, 'visualized_layer')\n",
        "model.layers[-1].activation = tf.keras.activations.linear\n",
        "model = utils.apply_modifications(model)"
      ],
      "metadata": {
        "id": "aPVSc7O9Gp09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get the input image index\n",
        "from tf_keras_vis.utils.scores import CategoricalScore\n",
        "#cat - 281, dog -235 , hen -8, tiger - 292\n",
        "score = CategoricalScore([56, 35, 8 , 92])"
      ],
      "metadata": {
        "id": "W7XHSAExA1On"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import cm\n",
        "from tf_keras_vis.gradcam import Gradcam\n",
        "\n",
        "input_classes = ['Covid19', 'Normal', 'Pneu_bac', 'Pneu_vir']\n",
        "\n",
        "input_images = preprocess_input(images)\n",
        "\n",
        "# Create Gradcam object\n",
        "gradcam = Gradcam(model,\n",
        "                  clone=True)\n",
        "\n",
        "# Generate heatmap with GradCAM\n",
        "cam = gradcam(score,\n",
        "              input_images,\n",
        "              penultimate_layer= -1)"
      ],
      "metadata": {
        "id": "695S6EB0A804"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#show generated images\n",
        "f, ax = plt.subplots(nrows=1, ncols=4, figsize=(12, 4))\n",
        "for i, img_class in enumerate(input_classes):\n",
        "    heatmap = np.uint8(cm.jet(cam[i])[..., :4] * 255)\n",
        "    ax[i].set_title(img_class, fontsize=16)\n",
        "    ax[i].imshow(images[i])\n",
        "    ax[i].imshow(heatmap, cmap='jet', alpha=0.5) # overlay\n",
        "    ax[i].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YQ_UJB-xBYMf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}